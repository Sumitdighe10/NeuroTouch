{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6eWII1GRnQA",
        "outputId": "f3a26d7f-00f8-4a68-80d2-01dc8bfbe5d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.23.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.69.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import gradio as gr\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# STEP 2: Load Final Dataset\n",
        "df = pd.read_csv(\"final_multimodal_dataset.csv\")\n",
        "\n",
        "# STEP 3: Normalize fatigue labels to 0-based indexing\n",
        "unique_fatigue_levels = sorted(df[\"fatigue_level\"].unique())\n",
        "fatigue_mapping = {val: idx for idx, val in enumerate(unique_fatigue_levels)}\n",
        "df[\"fatigue_level\"] = df[\"fatigue_level\"].map(fatigue_mapping)\n",
        "\n",
        "# STEP 4: Prepare Inputs and Labels\n",
        "columns_to_drop = [\n",
        "    \"timestamp_x\", \"timestamp_rounded\", \"emotion_label\", \"classification\",\n",
        "    \"mood_score\", \"fatigue_level\", \"source_file_x\", \"source_file_y\"\n",
        "]\n",
        "\n",
        "features = df.drop(columns=columns_to_drop, errors='ignore')\n",
        "features = features.select_dtypes(include=[np.number])\n",
        "\n",
        "if \"hrv_ms\" not in features.columns:\n",
        "    if \"hrv_sec\" in df.columns:\n",
        "        df[\"hrv_ms\"] = df[\"hrv_sec\"] * 1000\n",
        "    else:\n",
        "        df[\"hrv_ms\"] = 50.0\n",
        "    features[\"hrv_ms\"] = df[\"hrv_ms\"]\n",
        "\n",
        "x = features.values.astype(np.float32)\n",
        "y_mood = df[\"mood_score\"].values.astype(np.float32)\n",
        "y_fatigue = df[\"fatigue_level\"].values.astype(np.int64)\n",
        "\n",
        "# STEP 5: Define Model\n",
        "class NeuroModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.reg_head = nn.Linear(16, 1)\n",
        "        self.cls_head = nn.Linear(16, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        mood = self.reg_head(x)\n",
        "        fatigue = self.cls_head(x)\n",
        "        return mood, fatigue\n",
        "\n",
        "# STEP 6: Train Model\n",
        "x_train, x_test, y_train_mood, y_test_mood, y_train_fatigue, y_test_fatigue = train_test_split(\n",
        "    x, y_mood, y_fatigue, test_size=0.2, random_state=42, stratify=y_fatigue\n",
        ")\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(x_train), torch.tensor(y_train_mood), torch.tensor(y_train_fatigue)\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "input_size = x.shape[1]\n",
        "num_classes = len(np.unique(y_fatigue))\n",
        "model = NeuroModel(input_size=input_size, num_classes=num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_reg = nn.MSELoss()\n",
        "loss_cls = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb_mood, yb_fatigue in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        mood_pred, fatigue_pred = model(xb.float())\n",
        "        loss = loss_reg(mood_pred.squeeze(), yb_mood.float()) + loss_cls(fatigue_pred, yb_fatigue) * 1.5\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Save final model\n",
        "torch.save(model.state_dict(), \"neurotouch_model.pt\")\n",
        "\n",
        "# STEP 7: GPT Summary Generator\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def generate_gpt_summary(entry):\n",
        "    mood = entry['mood_score']\n",
        "    fatigue = entry['fatigue_level']\n",
        "    screen_time = entry['inputs']['screen_time_min']\n",
        "    valence = entry['inputs']['valence_score']\n",
        "    hrv = entry['inputs']['hrv_ms']\n",
        "    tone = \"positive and energetic\" if mood > 7 else (\"mindful and reflective\" if fatigue == 1 else \"exhausted and subdued\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Write a short, friendly summary about the user's mental state today.\n",
        "    - Mood Score: {mood}/10\n",
        "    - Fatigue Level: {fatigue}\n",
        "    - HRV: {hrv} ms\n",
        "    - Screen Time: {screen_time} minutes\n",
        "    - Valence: {valence}\n",
        "    Use a tone that feels {tone}.\n",
        "    \"\"\"\n",
        "\n",
        "    client = openai.OpenAI()\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=200,\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# STEP 8: Gradio Inference Function\n",
        "def predict_neurotouch(alpha, beta, theta, hrv_ms, tap_speed, swipe_velocity, tap_pressure, screen_time_min,\n",
        "                       unlock_freq, avg_key_hold_time, avg_key_interval, typo_rate, valence_score, mood_prev,\n",
        "                       attention_prev):\n",
        "    with torch.no_grad():\n",
        "        input_values = [\n",
        "            alpha, beta, theta, hrv_ms, tap_speed, swipe_velocity, tap_pressure, screen_time_min, unlock_freq,\n",
        "            avg_key_hold_time, avg_key_interval, typo_rate, valence_score, mood_prev, attention_prev\n",
        "        ]\n",
        "        input_tensor = torch.tensor([input_values], dtype=torch.float32)\n",
        "        mood_pred, fatigue_pred = model(input_tensor)\n",
        "        mood_score = float(mood_pred.item())\n",
        "        mood_score = max(1.0, min(mood_score, 10.0))\n",
        "        fatigue_level = int(torch.argmax(fatigue_pred).item())\n",
        "\n",
        "        # --- Heuristic Corrections ---\n",
        "        correction_notes = []\n",
        "\n",
        "        if hrv_ms < 30:\n",
        "            fatigue_level = 2\n",
        "            mood_score = min(mood_score, 6.0)\n",
        "            correction_notes.append(\"Low HRV: Set fatigue=2, cap mood to 6\")\n",
        "        elif hrv_ms < 40 and screen_time_min > 480:\n",
        "            fatigue_level = max(fatigue_level, 2)\n",
        "            mood_score = min(mood_score, 5.5)\n",
        "            correction_notes.append(\"HRV < 40 & high screen time: Fatigue boosted\")\n",
        "        elif fatigue_level == 2 and hrv_ms >= 40 and screen_time_min < 400:\n",
        "            fatigue_level = 1\n",
        "            correction_notes.append(\"HRV ok & low screen time: fatigue downgraded\")\n",
        "\n",
        "        if fatigue_level == 0 and valence_score < 0.3 and mood_score <= 6 and screen_time_min > 300:\n",
        "            fatigue_level = 1\n",
        "            correction_notes.append(\"Low valence + screen time: Fatigue nudged to 1\")\n",
        "\n",
        "        if valence_score < 0.3 and mood_score > 8 and mood_prev <= 6:\n",
        "            mood_score = min(mood_score, 6.5)\n",
        "            correction_notes.append(\"Mood overestimated: reduced to 6.5\")\n",
        "\n",
        "        if hrv_ms < 50 and screen_time_min > 300 and valence_score < 0.3:\n",
        "            fatigue_level = max(fatigue_level, 1)\n",
        "            correction_notes.append(\"Combo screen time+low HRV+valence: Fatigue = 1\")\n",
        "\n",
        "        if fatigue_level == 2:\n",
        "            feedback = \"âš ï¸ High fatigue detected â€” take a break ðŸ§˜\"\n",
        "        elif mood_score > 7:\n",
        "            feedback = \"âš¡ Mood is elevated, great energy today!\"\n",
        "        else:\n",
        "            feedback = \"ðŸ§© Mixed signals â€” stay mindful.\"\n",
        "\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"mood_score\": round(mood_score, 2),\n",
        "            \"fatigue_level\": fatigue_level,\n",
        "            \"feedback\": feedback,\n",
        "            \"inputs\": {\n",
        "                \"alpha\": alpha, \"beta\": beta, \"theta\": theta, \"hrv_ms\": hrv_ms,\n",
        "                \"tap_speed\": tap_speed, \"swipe_velocity\": swipe_velocity, \"tap_pressure\": tap_pressure,\n",
        "                \"screen_time_min\": screen_time_min, \"unlock_freq\": unlock_freq,\n",
        "                \"avg_key_hold_time\": avg_key_hold_time, \"avg_key_interval\": avg_key_interval,\n",
        "                \"typo_rate\": typo_rate, \"valence_score\": valence_score,\n",
        "                \"mood_prev\": mood_prev, \"attention_prev\": attention_prev\n",
        "            },\n",
        "            \"corrections\": correction_notes\n",
        "        }\n",
        "\n",
        "        with open(\"daily_log.json\", \"a\") as f:\n",
        "            f.write(json.dumps(log_entry) + \"\\n\")\n",
        "\n",
        "        summary = generate_gpt_summary(log_entry)\n",
        "\n",
        "        return {\n",
        "            \"Predicted Mood Score (1â€“10)\": round(mood_score, 2),\n",
        "            \"Fatigue Level (0â€“2)\": fatigue_level,\n",
        "            \"Feedback\": feedback,\n",
        "            \"Corrections Applied\": correction_notes,\n",
        "            \"Summary\": summary\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# STEP 9: Gradio UI\n",
        "with gr.Blocks(title=\"NeuroTouch Cognitive State Estimator\", theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"# ðŸ§  NeuroTouch Dashboard\\nEstimate cognitive state using EEG, HRV, and phone usage.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            alpha = gr.Number(label=\"Alpha Power\", value=0.5)\n",
        "            beta = gr.Number(label=\"Beta Power\", value=0.2)\n",
        "            theta = gr.Number(label=\"Theta Power\", value=0.3)\n",
        "            hrv = gr.Number(label=\"HRV (ms)\", value=50)\n",
        "            tap_speed = gr.Number(label=\"Tap Speed\", value=0.5)\n",
        "            swipe = gr.Number(label=\"Swipe Velocity\", value=1.0)\n",
        "            pressure = gr.Number(label=\"Tap Pressure\", value=0.85)\n",
        "            screen_time = gr.Number(label=\"Screen Time (min)\", value=300)\n",
        "\n",
        "        with gr.Column():\n",
        "            unlocks = gr.Number(label=\"Unlock Frequency\", value=100)\n",
        "            hold = gr.Number(label=\"Avg Key Hold Time\", value=0.2)\n",
        "            interval = gr.Number(label=\"Avg Key Interval\", value=0.27)\n",
        "            typo = gr.Number(label=\"Typo Rate\", value=0.05)\n",
        "            valence = gr.Number(label=\"Valence Score\", value=0.2)\n",
        "            mood_prev = gr.Number(label=\"Mood Score (Prev)\", value=6)\n",
        "            attention_prev = gr.Number(label=\"Attention Score (Prev)\", value=6)\n",
        "            submit = gr.Button(\"ðŸ§  Predict Mood & Fatigue\")\n",
        "\n",
        "    output = gr.JSON()\n",
        "    submit.click(fn=predict_neurotouch, inputs=[\n",
        "        alpha, beta, theta, hrv, tap_speed, swipe, pressure, screen_time,\n",
        "        unlocks, hold, interval, typo, valence, mood_prev, attention_prev\n",
        "    ], outputs=output)\n",
        "\n",
        "app.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "B4SnTnBOz0oe",
        "outputId": "fca4590a-9ca4-480c-f5b3-37a3a2a2ba34"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 1182.9760\n",
            "Epoch 2 - Loss: 868.1306\n",
            "Epoch 3 - Loss: 848.2549\n",
            "Epoch 4 - Loss: 813.4877\n",
            "Epoch 5 - Loss: 795.8335\n",
            "Epoch 6 - Loss: 795.0853\n",
            "Epoch 7 - Loss: 784.6788\n",
            "Epoch 8 - Loss: 768.6074\n",
            "Epoch 9 - Loss: 789.0066\n",
            "Epoch 10 - Loss: 775.5497\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://21cb0957e65ba9e9bc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://21cb0957e65ba9e9bc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://21cb0957e65ba9e9bc.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}